# データ使用量分析と最適化提案

## 現状のデータ使用量

### 🔴 最優先で最適化すべき（全データを使用、計算コストが非常に高い）

| 分析手法 | 現在のデータ使用量 | 計算コスト | 推奨データ量 | 削減効果 |
|---------|------------------|-----------|------------|---------|
| **t-SNE** | 全データ | 非常に高い（O(n²)） | 最新200-300件 | ⭐⭐⭐⭐⭐ |
| **PCA** | 全データ | 高い（O(n³)） | 最新200-300件 | ⭐⭐⭐⭐ |
| **変化点検出** | 全データ | 高い | 最新500件 | ⭐⭐⭐⭐ |
| **ネットワーク分析** | 全データ（2回ループ） | 高い | 最新500件 | ⭐⭐⭐⭐ |

### 🟡 次に最適化すべき（学習データが全データから生成される）

| 分析手法 | 現在のデータ使用量 | 計算コスト | 推奨データ量 | 削減効果 |
|---------|------------------|-----------|------------|---------|
| **ランダムフォレスト** | 過去100件の特徴量 + 全データで学習 | 非常に高い | 最新500件で学習 | ⭐⭐⭐⭐⭐ |
| **LightGBM** | 過去100件の特徴量 + 全データで学習 | 非常に高い | 最新500件で学習 | ⭐⭐⭐⭐⭐ |
| **スタッキング** | 過去100件の特徴量 + 全データで学習 | 非常に高い | 最新500件で学習 | ⭐⭐⭐⭐⭐ |
| **XGBoost** | 過去20件の特徴量 + 全データで学習 | 高い | 最新500件で学習 | ⭐⭐⭐⭐ |
| **LSTM** | 過去30件の特徴量 + 全データで学習 | 非常に高い（ニューラルネット） | 最新500件で学習 | ⭐⭐⭐⭐⭐ |

### 🟢 比較的軽量（最適化の優先度は低い）

| 分析手法 | 現在のデータ使用量 | 計算コスト | 備考 |
|---------|------------------|-----------|------|
| **HMM** | 全データ | 中程度 | 既に軽量 |
| **ARIMA** | 全データ | 中程度 | 既に軽量 |
| **カルマンフィルタ** | 全データ | 低い | 既に軽量 |
| **ウェーブレット変換** | 全データ | 中程度 | 既に軽量 |
| **連続性分析** | 全データ | 低い | 既に軽量 |

## 推奨される最適化方針

### 1. **t-SNE（最優先）**
- **現状**: 全データを使用（例: 1000件）
- **推奨**: 最新200-300件のみ使用
- **理由**: 計算量がO(n²)で、データ量が2倍になると計算時間が4倍になる
- **影響**: 予測精度への影響は最小限（最新データの方が重要）

### 2. **PCA（最優先）**
- **現状**: 全データを使用
- **推奨**: 最新200-300件のみ使用
- **理由**: 計算量がO(n³)で、データ量が2倍になると計算時間が8倍になる
- **影響**: 予測精度への影響は最小限

### 3. **機械学習モデル（ランダムフォレスト、LightGBM、スタッキング、XGBoost、LSTM）**
- **現状**: 過去100件（または20-30件）の特徴量 + 全データで学習
- **推奨**: 最新500件のみで学習
- **理由**: 
  - 機械学習モデルは最新のデータパターンを学習する方が重要
  - 古いデータは予測にあまり寄与しない
  - 学習データ量を減らすことで、学習時間を大幅に短縮
- **影響**: 予測精度への影響は最小限（むしろ最新データに特化することで精度向上の可能性）

### 4. **変化点検出**
- **現状**: 全データを使用
- **推奨**: 最新500件のみ使用
- **理由**: 最近の変化点の方が予測に重要
- **影響**: 予測精度への影響は最小限

### 5. **ネットワーク分析**
- **現状**: 全データを使用（2回ループ）
- **推奨**: 最新500件のみ使用
- **理由**: 最近の遷移パターンの方が予測に重要
- **影響**: 予測精度への影響は最小限

## 実装方針

### データ量制限の設定方法

1. **固定件数制限**: 最新N件のみ使用（推奨）
   - 例: `recent_data = self.df.tail(500)`
   - シンプルで実装が容易

2. **期間ベース制限**: 最新N日間のみ使用
   - 例: `recent_data = self.df[self.df['date'] >= cutoff_date]`
   - データ更新頻度に依存しない

3. **ハイブリッド**: データ量が少ない場合は全データ、多い場合は制限
   - 例: `recent_data = self.df.tail(min(500, len(self.df)))`

### 期待される効果

- **t-SNE**: 計算時間を約1/10に短縮（1000件→200件）
- **PCA**: 計算時間を約1/8に短縮（1000件→200件）
- **機械学習モデル**: 学習時間を約1/2に短縮（1000件→500件）
- **変化点検出・ネットワーク分析**: 計算時間を約1/2に短縮（1000件→500件）

**総合的な効果**: 5時間 → 約1-2時間に短縮（60-80%の時間削減）

## 注意事項

1. **予測精度への影響**: 最新データに特化することで、むしろ予測精度が向上する可能性がある
2. **データ量が少ない場合**: データ量が推奨件数未満の場合は、全データを使用する
3. **段階的な実装**: 一度にすべてを変更せず、1つずつ実装して効果を確認することを推奨

